# 1.1. 决策树概述

## 1.1.1. 决策树是如何工作的

决策树（Decision Tree）是一种非参数的有监督学习方法，它能从一系列有特征和标签的数据中总结出决策规则，
并用树状图的结构在呈现这些规则，以解决分类和回归问题。决策树算法容易理解，适用各种数据，
在解决各种问题时都有良好表现，尤其是以树模型为核心的各种集成算法，在各个行业和领域都有广泛的应用。<br>
在决策过程中，我们一直对记录的特征进行提问。最初的问题所在地为**根节点**，得到结论前的每一个问题都是**中间节点**，
而得到的每一个结论都叫做**子节点**<br>

        决策树算法的核心是两个问题：
        1）如何从数据表中找出最佳节点和最佳分枝。
        2）如何让决策树停止生长，防止过拟合。

## 1.1.2. sklearn中的决策树

* 模块sklearn.tree
sklearn中决策树在tree这个模块下，总共5类：<br>

        tree.DecisionTreeClassifier：分类树
        tree.DecisionTreeRegressor：回归树
        tree.export_graphviz：将决策树导出为DOT格式，画图专用
        tree.ExtraTreeClassifier：高随机版本的分类树
        tree.ExtraTreeRegressor：高随机版本的回归树


* sklearn的基本建模流程
1. 实例化，建立评估模型对象<br>
2. 通过模型接口训练模型<br>
3. 通过模型接口提取需要的信息（如测试集结果）<br>

于是，分类树对应的代码是：<br>

```Python
from sklearn import tree  # 导入需要的模块
clf = tree.DecisionTreeClassifier()  # 1.实例化模型
clf = clf.fit(X_train, y_train)  # 2.把训练集数据通过接口放入模型进行训练
result = clf.score(X_test, y_test)  # 3. 导入测试集，从接口中调用需要的信息
```
